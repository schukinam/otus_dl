{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import utils\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./MNIST_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загружаем датасет MNIST, преобразуя в тензоры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(path, train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.MNIST(path, train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание: преобразовать train_data таким образом, чтобы полученный датасет обладал статистиками mean = 0 и std = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для решения задачи посчитаем текущие mean и std датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean([train_data[i][0].mean() for i in range(len(train_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13066047"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_std(train_data, train_mean):\n",
    "    # std = sqrt((x-mean)^2/(n-1))\n",
    "    all_squared_sums = 0\n",
    "    for i in range(len(train_data)):\n",
    "        tensor_of_squared_sums = (train_data[i][0].flatten() - train_mean)**2\n",
    "        all_squared_sums += tensor_of_squared_sums.sum()\n",
    "    number_of_images = len(train_data)\n",
    "    numbers_in_image = train_data[0][0].flatten().shape[0]\n",
    "    std = np.sqrt(all_squared_sums/(number_of_images*numbers_in_image-1))\n",
    "    return std.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_std = get_std(train_data, train_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3081079125404358"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Добавим в transformation pipeline новый трансформ и применим к данным:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((train_mean,), (train_std,)),\n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_n = datasets.MNIST(path, train=True, download=True, transform=mnist_transform)\n",
    "test_data_n = datasets.MNIST(path, train=False, download=True, transform=mnist_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Посчитаем mean и std для полученных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9513907e-08\n"
     ]
    }
   ],
   "source": [
    "train_mean_n = np.mean([train_data_n[i][0].mean() for i in range(len(train_data_n))])\n",
    "print(train_mean_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999986886978149\n"
     ]
    }
   ],
   "source": [
    "train_std_n = get_std(train_data_n, train_mean_n)\n",
    "print(train_std_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Получили требуемый результат\n",
    "#### \"Обучались\", вычисляя статистики, мы на датасете train. Посмотрим, какие статистики получились после применения преобразования к датасету test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0060178316\n"
     ]
    }
   ],
   "source": [
    "test_mean_n = np.mean([test_data_n[i][0].mean() for i in range(len(test_data_n))])\n",
    "print(test_mean_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0076992511749268\n"
     ]
    }
   ],
   "source": [
    "test_std_n = get_std(test_data_n, test_mean_n)\n",
    "print(test_std_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Видим, что статистики очень близки, что позволяет нам сделать предположение, что датасет train и test взяты из одного распределения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
